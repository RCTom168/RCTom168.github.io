---
layout: post
title: CS Build Week 1 LS K-Nearest Neighbors Model

image: /img/1024px-Flag_of_the_Governor_of_Hong_Kong_(1959â€“1997).svg.png
---

![KNN Visual.jpeg](/img/KNN Visual.jpeg)

## Introduction
  In the data science world, there are many different machine learning algorithms to choose from. Each one is unique in its function and complexity. 

Some of the most notable ones are:
  1) K-Means Clustering
  2) K-Nearest Neighbors
  3) Decision Tree Learning
  4) Naive Bayes Classifier
  5) DBSCAN Clustering
  
Today, I will be breaking down, analyzing, and recreating the K-Nearest Neighbors algorithm.


## What is the K-Nearest Neighbors Algorithm?
  The KNN alogrithm is a simple and versatile machine learning algorithm that has a wide range of applications. It can be used in industries such as finance, healthcare, and political science, as well as more niche fields like facial recognition, handwriting detection, image recognition, and video recognition. KNN is considered to be a non-parametric, instance-based learning form of pattern recognition used for both classification and regression. It falls under the umbrella of supervised learning algorithms, and operates on labeled datasets to predict either a class (as in classification) or a numerical value (as in regression)
